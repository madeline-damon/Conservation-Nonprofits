{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # To get the pages\n",
    "from bs4 import BeautifulSoup # and to process them\n",
    "from bs4.element import Comment\n",
    "\n",
    "from time import sleep      # Allowing us to pause between pulls\n",
    "from random import random   # And allowing that pause to be random\n",
    "\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions used for scraping code\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "##Creating a file name for each URL from the nonprofits\n",
    "def generate_filename_from_url(url) :\n",
    "    \n",
    "    if not url :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https\n",
    "    name = url.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "\n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # remove last underscore\n",
    "    last_underscore_spot = name.rfind(\"_\")\n",
    "    \n",
    "    name = name[:last_underscore_spot] + name[(last_underscore_spot+1):]\n",
    "\n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Nonprofits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a dictionary to store the links to each nonprofit's mission/vision/values statements\n",
    "\n",
    "small_nonprofit_pages = dict()\n",
    "\n",
    "small_nonprofit_pages[\"about_us\"] = \"\"\"\n",
    "https://www.sonoraninstitute.org/our-story/mission-vision/\n",
    "https://www.internationalconservation.org/about\n",
    "https://www.cecsb.org/about/our-mission/\n",
    "https://www.friends.org/about-us/our-story\n",
    "https://www.earthshare.org/about-earthshare/\n",
    "https://www.chattahoochee.org/about/\n",
    "https://www.conservationnw.org/about-us/\n",
    "https://www.qlf.org/about-qlf/mission-vision/\n",
    "https://www.globalgreen.org/\n",
    "https://www.sustainablenorthwest.org/focus\n",
    "\"\"\".split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 9.80 seconds.\n"
     ]
    }
   ],
   "source": [
    "for page in small_nonprofit_pages :  \n",
    "    for link in small_nonprofit_pages[page] : \n",
    "        output_file_name = generate_filename_from_url(link) #Using the function created above, create a file name\n",
    "        \n",
    "        # pull the page \n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # process the page if r status code is 200 (successful pull)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            texts=soup.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts)\n",
    "         # write out the page to a file with the appropriate name\n",
    "        with open(output_file_name,'w',encoding = \"UTF-8\") as outfile :\n",
    "            outfile.write(\" \".join(t.strip() for t in visible_texts))\n",
    "    \n",
    "        # Pause for a bit\n",
    "    wait_time = 5 + random()*10\n",
    "    print(f\"Waiting for {wait_time:.02f} seconds.\")\n",
    "        \n",
    "    sleep(wait_time)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_MVVs = [\n",
    "             \"www_cecsb_org_about_our-mission.txt\",\n",
    "             \"www_chattahoochee_org_about.txt\",\n",
    "             \"www_conservationnw_org_about-us.txt\",\n",
    "             \"www_earthshare_org_about-earthshare.txt\",\n",
    "             \"www_friends_org_about-usour-story.txt\",\n",
    "             \"www_globalgreen_org.txt\",\n",
    "             \"www_internationalconservation_orgabout.txt\",\n",
    "             \"www_qlf_org_about-qlf_mission-vision.txt\",\n",
    "             \"www_sonoraninstitute_org_our-story_mission-vision.txt\",\n",
    "             \"www_sustainablenorthwest_orgfocus.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium Nonprofits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a dictionary to store the links to each nonprofit's mission/vision/values statements\n",
    "\n",
    "medium_nonprofit_pages = dict()\n",
    "\n",
    "medium_nonprofit_pages[\"about_us\"] = \"\"\"\n",
    "https://www.wildearthguardians.org/about-us/mission-vision-history/\n",
    "https://www.wta.org/our-work/about\n",
    "https://www.ncascades.org/discover/north-cascades-institute\n",
    "https://www.pcta.org/about-us/our-mission-vision-and-values/\n",
    "https://www.pachamama.org/about/mission\n",
    "https://www.treepeople.org/our-work/\n",
    "https://www.mohonkpreserve.org/what-we-do/\n",
    "https://www.pecpa.org/about/\n",
    "https://www.stand.earth/about/mission-and-principles\n",
    "https://www.earthisland.org/index.php/aboutUs/about-earth-island\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connection:Certificate did not match expected hostname: www.ncascades.org. Certificate: {'subject': ((('commonName', 'ncascades.org'),),), 'subjectAltName': [('DNS', 'ncascades.org')]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 13.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "for page in medium_nonprofit_pages :  \n",
    "    for link in medium_nonprofit_pages[page] : \n",
    "        output_file_name = generate_filename_from_url(link) #Using the function created above, create a file name\n",
    "        \n",
    "        # pull the page \n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # process the page if r status code is 200 (successful pull)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            texts=soup.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts)\n",
    "         # write out the page to a file with the appropriate name\n",
    "        with open(output_file_name,'w',encoding = \"UTF-8\") as outfile :\n",
    "            outfile.write(\" \".join(t.strip() for t in visible_texts))\n",
    "    \n",
    "        # Pause for a bit\n",
    "    wait_time = 5 + random()*10\n",
    "    print(f\"Waiting for {wait_time:.02f} seconds.\")\n",
    "        \n",
    "    sleep(wait_time)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_nonprofits = [\"www_earthisland_org_index_php_aboutUsabout-earth-island.txt\",\n",
    "                    \"www_mohonkpreserve_org_what-we-do.txt\",\n",
    "                    \"www_ncascades_org_discovernorth-cascades-institute.txt\",\n",
    "                    \"www_pachamama_org_aboutmission.txt\",\n",
    "                    \"www_pcta_org_about-us_our-mission-vision-and-values.txt\",\n",
    "                    \"www_pecpa_org_about.txt\",\n",
    "                    \"www_stand_earth_aboutmission-and-principles.txt\",\n",
    "                    \"www_treepeople_org_our-work.txt\",\n",
    "                    \"www_wildearthguardians_org_about-us_mission-vision-history.txt\",\n",
    "                    \"www_wta_org_our-workabout.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Nonprofits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a dictionary to store the links to each nonprofit's mission/vision/values statements\n",
    "\n",
    "large_nonprofit_pages = dict()\n",
    "\n",
    "large_nonprofit_pages[\"about_us\"] = \"\"\"\n",
    "https://www.ceres.org/about-us\n",
    "https://www.cbf.org/about-cbf/our-mission/\n",
    "https://www.grownyc.org/about\n",
    "https://www.rmi.org/about/\n",
    "https://www.earthjustice.org/about\n",
    "https://www.rff.org/about/\n",
    "https://www.waterkeeper.org/who-we-are/\n",
    "https://www.tpwf.org/our-story/\n",
    "https://www.thesca.org/about\n",
    "https://www.climaterealityproject.org/our-mission\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 11.38 seconds.\n"
     ]
    }
   ],
   "source": [
    "for page in large_nonprofit_pages :  \n",
    "    for link in large_nonprofit_pages[page] : \n",
    "        output_file_name = generate_filename_from_url(link) #Using the function created above, create a file name\n",
    "        \n",
    "        # pull the page \n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # process the page if r status code is 200 (successful pull)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            texts=soup.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts)\n",
    "         # write out the page to a file with the appropriate name\n",
    "        with open(output_file_name,'w',encoding = \"UTF-8\") as outfile :\n",
    "            outfile.write(\" \".join(t.strip() for t in visible_texts))\n",
    "    \n",
    "        # Pause for a bit\n",
    "    wait_time = 5 + random()*10\n",
    "    print(f\"Waiting for {wait_time:.02f} seconds.\")\n",
    "        \n",
    "    sleep(wait_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_nonprofits = [\"www_cbf_org_about-cbf_our-mission.txt\",\n",
    "                    \"www_ceres_orgabout-us.txt\",\n",
    "                    \"www_climaterealityproject_orgour-mission.txt\",\n",
    "                    \"www_earthjustice_orgabout.txt\",\n",
    "                    \"www_grownyc_orgabout.txt\",\n",
    "                    \"www_rff_org_about.txt\",\n",
    "                    \"www_rmi_org_about.txt\",\n",
    "                    \"www_thesca_orgabout.txt\",\n",
    "                    \"www_tpwf_org_our-story.txt\",\n",
    "                    \"www_waterkeeper_org_who-we-are.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixing Error files that came up blank\n",
    "\n",
    "error_links= dict()\n",
    "\n",
    "error_links[\"about_us\"] = \"\"\"\n",
    "https://earthshare.org/about-earthshare/\n",
    "https://internationalconservation.org/about\n",
    "https://rmi.org/about/\n",
    "https://tpwf.org/our-story/\n",
    "https://pcta.org/about-us/our-mission-vision-and-values/\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 12.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "for page in error_links :  \n",
    "    for link in error_links[page] : \n",
    "        output_file_name = generate_filename_from_url(link) #Using the function created above, create a file name\n",
    "        \n",
    "        # pull the page \n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # process the page if r status code is 200 (successful pull)\n",
    "#         if r.status_code == 200:\n",
    "#             soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#             texts=soup.findAll(text=True)\n",
    "#             visible_texts = filter(tag_visible, texts)\n",
    "\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            texts=soup.findAll(text=True)\n",
    "            visible_texts = filter(tag_visible, texts)\n",
    "\n",
    "\n",
    "         # write out the page to a file with the appropriate name\n",
    "        with open(output_file_name,'w',encoding = \"Latin-1\") as outfile :\n",
    "            outfile.write(\" \".join(t.strip() for t in visible_texts))\n",
    "    \n",
    "        # Pause for a bit\n",
    "    wait_time = 5 + random()*10\n",
    "    print(f\"Waiting for {wait_time:.02f} seconds.\")\n",
    "        \n",
    "    sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Security Issue\n",
    "\n",
    "The five above links had some sort of security barrier: so I just copied and pasted MVVs from websites into new files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
